{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5b18f48b-9c9b-410f-8510-863452ad6c78",
   "metadata": {},
   "source": [
    "# CNNs and Computer Vision Notes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "081f03d3-5ded-41f1-a1b1-d85968a160dc",
   "metadata": {},
   "source": [
    "## Working with Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10c4914a-316c-44d1-b10d-f14c88b52115",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "\n",
    "# Set the seed for NumPy\n",
    "np.random.seed(42)\n",
    "\n",
    "# Set the seed for TensorFlow\n",
    "tf.random.set_seed(42)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e25f3646-4d01-44a7-8f96-e35f0dbf4c3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the mnist data from Keras\n",
    "from tensorflow.keras.datasets import mnist\n",
    "# Get data - it is already split into training and testing sets\n",
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b59fac7-5721-4c64-b115-e757c0d91729",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the dataype of X_train\n",
    "type(X_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59c0f118-1ecb-4e1c-af65-0f2776650642",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the shape of X_train\n",
    "X_train.shape\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae045989-2a43-45f1-aac3-5b70129e5804",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Previewing the type and shape of y_train\n",
    "print(type(y_train))\n",
    "y_train.shape\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "519c3dfe-a17a-45a0-b47f-34f42cea9449",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check first five values for y\n",
    "y_train[0:5]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03858e9c-24c3-4f3d-bbcf-a0219c7aefad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check Value Counts\n",
    "pd.Series(y_train).value_counts()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f23dda1b-83b3-497a-8b47-472cf7cde2e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking the shape of a single image\n",
    "img = X_train[0]\n",
    "img.shape\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b51d239c-e4ba-43c1-9285-9105b1c83ba0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Viewing the values stored in the array for a single image\n",
    "img\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26cce5a3-2350-437a-82d4-a54b002b89a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Range of values for light intensity\n",
    "np.min(img), np.max(img)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11451997-c596-47da-a140-51674edd47a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the data as an image\n",
    "plt.imshow(img);\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "893fed9e-e6dd-4762-83ca-376d63f37de6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the data as an image\n",
    "plt.imshow(img, cmap=\"gray\")\n",
    "plt.axis(\"off\");\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff0b6ad8-89c5-46f2-a601-c377b9cd7fce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To filter for rows that are 1's:\n",
    "idx_1s = y_train == 1\n",
    "idx_1s.sum()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67c14a2b-4d3b-4a0a-8374-72818a99cda1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Proving we've isolated the 1's\n",
    "y_train[idx_1s]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "461e1e35-4788-46fd-8e68-a4e61e4a2d94",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Viewing the image data for 1's\n",
    "X_train[idx_1s]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47a9afae-09a2-46bc-955a-769f7162d8a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizing the first \"1\"\n",
    "plt.imshow(X_train[idx_1s][0], cmap=\"gray\")\n",
    "plt.axis(\"off\");\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7aeee5b8-614e-461b-a2c2-ea2e4ebd71eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting the list of unique classes\n",
    "classes = np.unique(y_train)\n",
    "classes\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b3388db-64ce-48dc-a625-c27971f4f6ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(ncols=10, figsize=(8, 1.5))  \n",
    "\n",
    "for i, digit in enumerate(classes):\n",
    "    # Get the axes\n",
    "    ax = axes[i]\n",
    "    # Filter for the current digit\n",
    "    idx_digit = y_train == digit\n",
    "    # Plot the first example digit\n",
    "    ax.imshow(X_train[idx_digit][0], cmap=\"gray\")\n",
    "    ax.axis(\"off\")\n",
    "fig.tight_layout()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93efdd99-7b84-44c1-94ae-da0616f4ef37",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting 10 examples of each digit\n",
    "n_example_rows = 10\n",
    "fig, axes = plt.subplots(ncols=10, nrows=n_example_rows, figsize=(8, 8))\n",
    "# axes = axes.flatten()x\n",
    "for row in range(n_example_rows):\n",
    "    row_axes = axes[row]\n",
    "    for i, digit in enumerate(classes):\n",
    "        # Get the axes\n",
    "        ax = row_axes[i]\n",
    "        # Filter for the current digit\n",
    "        idx_digit = y_train == digit\n",
    "        # Plot the first example digit\n",
    "        ax.imshow(X_train[idx_digit][row], cmap=\"gray\")\n",
    "        ax.axis(\"off\")\n",
    "fig.tight_layout()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fabc27c3-c197-45cd-b476-a8ec1a6be04a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# New imports\n",
    "from tensorflow.keras.preprocessing.image import (array_to_img, img_to_array, load_img, save_img)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c287c4b3-441a-4254-b7cf-1db5b6cae875",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try to view image with tensorflow\n",
    "array_to_img(X_train[0])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a52eddd-f9bb-4652-a77f-e1af9e1aaa76",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Viewing shape before reshaping\n",
    "img.shape\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51463b61-48ed-4c20-8ddf-15c545ebef19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving the new dimensions of the new shape\n",
    "new_shape = (*img.shape, 1)\n",
    "new_shape\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d395a800-091b-4d58-943a-474a42baa677",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reshaping the image\n",
    "reshaped_img = img.reshape(new_shape)\n",
    "reshaped_img.shape\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a43334fd-b5ed-4ed6-a9d3-09e4d252cd64",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show image\n",
    "array_to_img(reshaped_img)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "314dd8b1-87b0-4536-8d85-ad37516b1c64",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding extra final dimension  with tf.newaxis\n",
    "X_train_reshaped_alt = X_train[...,tf.newaxis]\n",
    "X_train_reshaped_alt.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2bdbe82-dd47-4460-8dd1-6f8f7c853b24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Showing first image from reshaped data\n",
    "img_reshaped_alt = X_train_reshaped_alt[0]\n",
    "array_to_img(img_reshaped_alt)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b55c754-97be-4c46-bba2-1eafa07e1a01",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "url = \"https://upload.wikimedia.org/wikipedia/commons/d/d7/RGB_24bits_palette_sample_image.jpg\"\n",
    "resp = requests.get(url)\n",
    "fname = \"example-color-image.png\"\n",
    "with open(fname,'wb') as f:\n",
    "    f.write(resp.content)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0c948d6-c83c-4a87-96db-2d0737e391ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the file as a PIL Image using tensorflow's load_img\n",
    "color_img = load_img(fname)\n",
    "color_img\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64403c76-36aa-4ab8-ba16-b49cb86272d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting the color image to an array\n",
    "color_img_data= img_to_array(color_img)\n",
    "color_img_data.shape\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d026090-64a1-43a0-954c-9e0030ce6974",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Viewing the pixel values for the first channel\n",
    "channel0 = color_img_data[:,:,0]\n",
    "channel0.shape\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "147f2e7c-8410-4a0f-ab97-4a69c230201a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the red channel\n",
    "fig, axes = plt.subplots()\n",
    "axes.imshow(color_img_data[:,:,0], cmap='gray')\n",
    "axes.set_title(\"Channel: Red\");\n",
    "axes.axis('off');\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "812803e6-0868-49d1-bd60-ee014f6459bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# loop through all 3 colors\n",
    "fig, axes = plt.subplots(ncols=3, figsize=(10,4))\n",
    "channels = ['red','green','blue']\n",
    "for i, channel in enumerate(channels):\n",
    "    axes[i].imshow(color_img_data[:,:,i], cmap='gray')\n",
    "    axes[i].set_title(f\"Channel: {channel}\");\n",
    "    axes[i].axis('off')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ce70db5-1b1b-4a99-81c5-928ac0e57f2a",
   "metadata": {},
   "source": [
    "## CNNS in Python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec3cb154-09c5-4db4-ba3e-d337299f6442",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from tensorflow.keras.datasets import mnist\n",
    "from tensorflow.keras.layers import Conv2D, Dense, Flatten, MaxPooling2D\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eee48cd8-7c5b-4fe3-9c74-d203f70bd00f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom function for plotting each metric\n",
    "def plot_history(history, figsize=(6,12), marker='o'):\n",
    "       \n",
    "    # Get list of metrics from history\n",
    "    metrics = [c for c in history.history if not c.startswith('val_')]\n",
    "    \n",
    "    ## Separate row for each metric\n",
    "    fig, axes = plt.subplots(nrows=len(metrics),figsize=figsize)\n",
    "    \n",
    "    # For each metric\n",
    "    for i, metric_name in enumerate(metrics):\n",
    "    \n",
    "        # Get the axis for the current metric\n",
    "        ax = axes[i]\n",
    "    \n",
    "        # Get metric from history.history\n",
    "        metric_values = history.history[metric_name]\n",
    "        # Get epochs from history\n",
    "        epochs = history.epoch\n",
    "    \n",
    "        # Plot the training metric\n",
    "        ax.plot(epochs, metric_values, label=metric_name, marker=marker)\n",
    "    \n",
    "        ## Check if val_{metric} exists. if so, plot:\n",
    "        val_metric_name = f\"val_{metric_name}\"\n",
    "        if val_metric_name in history.history:\n",
    "            # Get validation values and plot\n",
    "            metric_values = history.history[val_metric_name]\n",
    "            ax.plot(epochs,metric_values,label=val_metric_name, marker=marker)\n",
    "    \n",
    "        # Final subplot adjustments \n",
    "        ax.legend()\n",
    "        ax.set_title(metric_name)\n",
    "    fig.tight_layout()\n",
    "    return fig, axes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f5d35cf-6f02-4272-8799-a75681c97dd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, ConfusionMatrixDisplay\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def classification_metrics(y_true, y_pred, label='',\n",
    "                           output_dict=False, figsize=(8,4),\n",
    "                           normalize='true', cmap='Blues',\n",
    "                           colorbar=False):\n",
    "    \n",
    "    # Get the classification report\n",
    "    report = classification_report(y_true, y_pred)\n",
    "    ## Print header and report\n",
    "    header = \"-\"*70\n",
    "    print(header, f\" Classification Metrics: {label}\", header, sep='\\n')\n",
    "    print(report)\n",
    "    \n",
    "    ## CONFUSION MATRICES SUBPLOTS\n",
    "    fig, axes = plt.subplots(ncols=2, figsize=figsize)\n",
    "    \n",
    "    # create a confusion matrix  of raw counts\n",
    "    ConfusionMatrixDisplay.from_predictions(y_true, y_pred,\n",
    "                normalize=None, cmap='gist_gray', values_format=\"d\", colorbar=colorbar,\n",
    "                ax = axes[0],);\n",
    "    axes[0].set_title(\"Raw Counts\")\n",
    "    \n",
    "    # create a confusion matrix with the test data\n",
    "    ConfusionMatrixDisplay.from_predictions(y_true, y_pred,\n",
    "                normalize=normalize, cmap=cmap, values_format=\".2f\", colorbar=colorbar,\n",
    "                ax = axes[1]);\n",
    "    axes[1].set_title(\"Normalized Confusion Matrix\")\n",
    "    \n",
    "    # Adjust layout and show figure\n",
    "    fig.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Return dictionary of classification_report\n",
    "    if output_dict==True:\n",
    "        report_dict = classification_report(y_true, y_pred, output_dict=True)\n",
    "        return report_dict\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec5bbb4e-02ae-4f9b-932e-fae909cbda36",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the mnist data from Keras\n",
    "from tensorflow.keras.datasets import mnist\n",
    "# Get data - it is already split into training and testing sets\n",
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23d60b15-e33e-4fea-a262-94c706cca3f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check shape\n",
    "X_train.shape\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4723751-9f74-4f4b-a2c2-6e5bd2f2b15a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check shape\n",
    "X_train.shape\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d1df8b2-7aa7-4603-8a4e-dc67bc1b43e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reshape data\n",
    "X_train = X_train[..., tf.newaxis]\n",
    "X_test = X_test[..., tf.newaxis]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b76fa62-67bb-458d-881e-691c69deabaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confirming new shape\n",
    "X_train.shape\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe79ab9b-cd81-43b0-9611-1d1c372f2709",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Viewing the first label in original y_train\n",
    "y_train[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd0e1750-c923-43d1-90a0-2ce496d445f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create One-Hot-Encoded target for Tensorflow\n",
    "y_train = to_categorical(y_train)\n",
    "y_test = to_categorical(y_test)\n",
    "y_train[0]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "100650b0-a9e5-4255-8082-177d4866e08d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Define our network structure\n",
    "# Save the input shape (skip the number of images)\n",
    "input_shape = X_train.shape[1:]\n",
    "input_shape\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38147ff1-68cd-4393-8446-e646a70f3f89",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sequential model\n",
    "model = Sequential()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2bbbafc-ff54-40a6-895f-4601860c37a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import layers\n",
    "# Using rescaling layer to scale pixel values\n",
    "scaling_layer = layers.Rescaling(1./255, input_shape=input_shape)\n",
    "model.add(scaling_layer)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a7e010b-256a-4277-bf96-9a94254fc6e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convolutional layer\n",
    "model.add(\n",
    "    Conv2D(\n",
    "        filters=8,  # How many filters you want to use\n",
    "        kernel_size=3,  # size of each filter\n",
    "        input_shape=input_shape,  # What is the shape of your input features (we defined this above)\n",
    "    )\n",
    ") \n",
    "# Pooling layer\n",
    "model.add(MaxPooling2D(pool_size=2))  # Size of pooling\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69352777-0161-46f8-a636-905c207537d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Flattening layer\n",
    "model.add(Flatten())\n",
    "# Output layer\n",
    "model.add(\n",
    "    Dense(10, activation=\"softmax\")  # How many output possibilities we have\n",
    ")  # What activation function are you using?\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aebc026e-d329-4329-9863-5aae239cc01f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check model summary\n",
    "model.summary()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0022bb66-fc1e-481e-8847-e282a276d8a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Compile\n",
    "model.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\", \n",
    "              metrics=[\"accuracy\"])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acf15323-48c6-48e7-b484-a55fa3283d05",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: Fit our model\n",
    "history = model.fit(X_train, y_train, \n",
    "                    validation_split=.2,\n",
    "                    epochs=10)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ce839dc-09a1-4804-893e-085598a9bbf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Call custom function to plot metrics\n",
    "plot_history(history);\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fae99354-66de-49a3-8ad6-2990882caed8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate test data with model\n",
    "model.evaluate(X_test, y_test, return_dict=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c21621c8-3252-415c-963d-9d7d892f301c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get predictions for sklearn metrics\n",
    "y_test_pred = model.predict(X_test)\n",
    "y_test_pred[0]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ec12944-374b-4b32-8f7f-1ef49460701a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sum all the values for the first prediction\n",
    "sum(y_test_pred[0])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f16ede9c-ab90-4929-9056-95c62ff2ba32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the max value\n",
    "max(y_test_pred[0])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30ed1702-993f-4ebb-9987-7d3627ca1e1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find index at the max value\n",
    "y_test_pred[0].argmax()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dcf06c9-b7fa-473b-a6bd-87b962445da4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting Sklearn Metrics\n",
    "classification_metrics(y_test.argmax(axis=1), y_test_pred.argmax(axis=1),\n",
    "                          label='Test Data',\n",
    "                         figsize=(10,8))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ebad307-799f-45ce-931d-b3953a51935a",
   "metadata": {},
   "source": [
    "# TensorFlow Dataset Objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1feaccd1-f700-4ca0-9326-62d8a4a45b03",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "# Set the seed for NumPy\n",
    "np.random.seed(42)\n",
    "# Set the seed for TensorFlow\n",
    "tf.random.set_seed(42)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c03f0230-8da0-47a8-9357-5df42d883d06",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, glob\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import PIL\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.utils import load_img, img_to_array, array_to_img\n",
    "from tensorflow.keras import layers, models\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dd06fd1-9ed0-46f4-a7de-8ae3f8ce565d",
   "metadata": {},
   "source": [
    "# Note: Have to find a way to unzip folder into notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6f53e64c-6bdd-4d83-bd7b-44c6ea435a4f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Data/xrays/'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking the contents of xrays folder\n",
    "data_dir = \"Data/xrays/\"\n",
    "data_dir\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cea2d6fc-519c-4460-aab7-1e240560ccb1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Gettting the list of folders from data dir\n",
    "subfolders = os.listdir(data_dir)\n",
    "subfolders\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e178c15a-824a-4027-9b6d-082998363214",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (2034360810.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn[11], line 1\u001b[1;36m\u001b[0m\n\u001b[1;33m    unzip \"~/Data/xray_archive.zip\"\u001b[0m\n\u001b[1;37m          ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "unzip \"~/Data/xray_archive.zip\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2dd8bb46-85da-438c-bb72-5bee9d2cd9aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Getting list of img file paths (no folders)\n",
    "img_files = glob.glob(data_dir+\"**/*\")\n",
    "len(img_files)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82698307-eeb0-4c76-ba08-e08398a485a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Take a look at the first 5 filepaths\n",
    "img_files[0:5]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7710001-29e6-492b-955f-ff026134cdb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preview an example image (at full size)\n",
    "img_loaded = load_img(img_files[0])\n",
    "img_data = img_to_array(img_loaded)\n",
    "img_data.shape\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8742d660-6a92-4e0f-acd6-ad940b7e93ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data can be converted back to image\n",
    "array_to_img(img_data)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4da5d74e-8442-4b89-aba9-a00aff9d4004",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving image params as vars for reuse\n",
    "batch_size = 32\n",
    "img_height = 96\n",
    "img_width = 96\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "732295e3-1553-46f3-a72c-e4e61cb8b6a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make the dataset from the main folder of images\n",
    "ds = tf.keras.utils.image_dataset_from_directory(\n",
    "  data_dir,\n",
    "    shuffle=True,\n",
    "    label_mode='categorical',\n",
    "  seed=123,\n",
    "  image_size=(img_height, img_width),\n",
    "  batch_size=batch_size)\n",
    "ds\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "814791d3-3fa5-414b-8cd9-ab3552542472",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Determine number of batches in dataset\n",
    "ds_size = len(ds)\n",
    "ds_size\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08aa1b42-9b4e-4dae-b5d8-c5e6e1572a0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# taking a sample batch to see batch shape\n",
    "example_batch_imgs,example_batch_y= ds.take(1).get_single_element()\n",
    "example_batch_imgs.shape\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec349233-f4ee-48ed-a5e7-2e7949e3c7d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preview y for first 5 of first batch\n",
    "example_batch_y[0:5]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa51b444-5e32-4588-83c7-5c2f092ee232",
   "metadata": {},
   "outputs": [],
   "source": [
    "# checking the class names\n",
    "class_names = ds.class_names\n",
    "class_names\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a739c96e-da9e-4bb6-b023-87d95c759b80",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving # of classes for reuse\n",
    "num_classes = len(class_names)\n",
    "num_classes\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3570fa71-49d2-4287-aa26-cd00f0cfe7f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving dictionary of integer:string labels\n",
    "class_dict = dict(zip(range(num_classes), class_names))\n",
    "class_dict\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0009d3c9-8ae5-49b4-a165-d0ced2f70c3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Individual image shape\n",
    "input_shape = example_batch_imgs[0].shape\n",
    "input_shape\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ffa2618-575c-4fd0-bb59-b38c8c080532",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Demo Unpacking shape\n",
    "input_shape = [*input_shape]\n",
    "input_shape\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc1c0c42-20ca-458e-bc44-5086bd8273ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the ratio of the train, validation, test split\n",
    "split_train = 0.7\n",
    "split_val = 0.2\n",
    "split_test = .1 \n",
    "# Calculate the number of batches for training and validation data \n",
    "n_train_batches =  int(ds_size * split_train)\n",
    "n_val_batches = int(ds_size * split_val)\n",
    "print(f\"Use {n_train_batches} batches as training data\")\n",
    "print(f\"Use {n_val_batches} batches as validation data\")\n",
    "print(f\"The remaining {len(ds)- (n_train_batches+n_val_batches)} batches will be used as test data.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b6e3f18-8351-45ce-a6f4-dad6459db015",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use .take to slice out the number of batches \n",
    "train_ds = ds.take(n_train_batches)\n",
    "# Confirm the length of the training set\n",
    "len(train_ds)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76b60b08-4d55-4c57-9cc0-32b64bfb54ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Skipover the training batches\n",
    "val_ds = ds.skip(n_train_batches)\n",
    "# Take the correct number of validation batches\n",
    "val_ds = val_ds.take(n_val_batches)\n",
    "# Confirm the length of the validation set\n",
    "len(val_ds)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24de28ac-5a69-4365-ae95-7592e3f9bb04",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Skip over all of the training + validation batches\n",
    "test_ds = ds.skip(n_train_batches + n_val_batches)\n",
    "# Confirm the length of the testing data\n",
    "len(test_ds)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "210d1f26-bc6c-4065-874f-7730fe525271",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The original (non-take/non-skip) dataset contains the class_names\n",
    "class_names  = ds.class_names\n",
    "class_names\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a42cef5-0e6a-4c12-993d-8bec167ab83e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write the building and compiling steps within a function\n",
    "def build_model():\n",
    "    # Instantatie model\n",
    "    model = models.Sequential()\n",
    "    # Scaling layer\n",
    "    scaling_layer = layers.Rescaling(1./255, input_shape=input_shape)\n",
    "    model.add(scaling_layer)\n",
    "    \n",
    "    # Convolutional layer\n",
    "    model.add(\n",
    "        layers.Conv2D(\n",
    "            filters=8,  # How many filters you want to use\n",
    "            kernel_size=3,  # size of each filter\n",
    "            input_shape=input_shape,\n",
    "            padding='same'\n",
    "        )) \n",
    "    # Pooling layer\n",
    "    model.add(layers.MaxPooling2D(pool_size=2))  # Size of pooling\n",
    "    # Convolutional layer\n",
    "    model.add(\n",
    "        layers.Conv2D(\n",
    "            filters=8,  # How many filters you want to use\n",
    "            kernel_size=3,  # size of each filter\n",
    "            input_shape=input_shape,\n",
    "            padding='same'\n",
    "        )) \n",
    "    # Pooling layer\n",
    "    model.add(layers.MaxPooling2D(pool_size=2))  # Size of pooling\n",
    "    \n",
    "    # Flattening layer\n",
    "    model.add(layers.Flatten())\n",
    "    # Output layer\n",
    "    model.add(\n",
    "        layers.Dense(3, activation=\"softmax\")  # How many output possibilities we have\n",
    "    )  # What activation function are you using?\n",
    "    \n",
    "    model.compile(optimizer='adam',\n",
    "                  loss='categorical_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "    \n",
    "    model.summary()\n",
    "    return model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3ba3658-ad62-4eb4-9b1e-3aa17ba599e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the model\n",
    "model1 = build_model()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "274556fe-3e1d-42db-8f65-ca75747d59d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime as dt\n",
    "# timing\n",
    "start = dt.datetime.now()\n",
    "    \n",
    "# fit the neural network\n",
    "epochs=5\n",
    "history = model1.fit(\n",
    "    train_ds,\n",
    "    validation_data=val_ds,\n",
    "    epochs=epochs, \n",
    ")\n",
    "    \n",
    "end = dt.datetime.now()\n",
    "dur = end-start\n",
    "print(f\"Training time: {dur}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e512acb9-5082-4496-9f3f-2826b295db29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use autotune to automatically determine best buffer sizes \n",
    "AUTOTUNE = tf.data.AUTOTUNE\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8598ae27-3b31-44ed-b0ef-44c4ea90f7eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make buffer size the same as the number of batches in train_ds\n",
    "buffer_size = len(train_ds)\n",
    "buffer_size\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "912881fe-181d-4505-a386-ff7daff29343",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optimize training data\n",
    "train_ds = train_ds.cache().shuffle(buffer_size= buffer_size,\n",
    "                                   seed=42).prefetch(buffer_size=AUTOTUNE)\n",
    "# Optimize validation data\n",
    "val_ds = val_ds.cache().prefetch(buffer_size=AUTOTUNE)\n",
    "# Optimize teset data\n",
    "test_ds = test_ds.cache().prefetch(buffer_size=AUTOTUNE)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "362cce8a-54ac-445e-af55-90a05ee17e00",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Call build function to create identical model\n",
    "model2 = build_model()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c8bcffd-7dfb-4d95-9d50-811509992da3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# See how long it takes to fit the optimized dataset\n",
    "# timing\n",
    "start = dt.datetime.now()\n",
    "# fit the neural network\n",
    "epochs=5\n",
    "history = model2.fit(\n",
    "  train_ds,\n",
    "  validation_data=val_ds,\n",
    "  epochs=epochs, \n",
    ")\n",
    "end = dt.datetime.now()\n",
    "dur2 = end-start\n",
    "print(f\"Training time: {dur2}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5214d7c-6b29-4a0c-a06a-c8b79bcc597d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"The optimized dataset was {dur/dur2:.2f} times faster!\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3abf0a40-3143-43dc-870a-5d35c1fbadcd",
   "metadata": {},
   "source": [
    "# Flexible Evaluation Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0430f6ff-6488-4147-99b0-7218eda88ed9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iterating through dataset object to separate image data from label data\n",
    "for images, labels in test_ds.as_numpy_iterator():\n",
    "    print(f'Image data shape is {images.shape}')\n",
    "    print(f'Label data shape is {labels.shape}')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "676226f7-9ac5-4e31-9edb-3a90e6f05558",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Previewing a label (y_true)\n",
    "labels[0]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bdb3650-5437-4a29-93f6-cc0d9291f6a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtain predictions from images\n",
    "y_probs = model2.predict(images, batch_size=1)\n",
    "y_probs[0]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd1b70af-f951-41ad-bc47-9bd9d23e7aeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_true_pred_labels(model,ds):\n",
    "    \"\"\"Gets the labels and predicted probabilities from a Tensorflow model and Dataset object.\n",
    "    Adapted from source: https://stackoverflow.com/questions/66386561/keras-classification-report-accuracy-is-different-between-model-predict-accurac\n",
    "    \"\"\"\n",
    "    y_true = []\n",
    "    y_pred_probs = []\n",
    "    \n",
    "    # Loop through the dataset as a numpy iterator\n",
    "    for images, labels in ds.as_numpy_iterator():\n",
    "        \n",
    "        # Get prediction with batch_size=1\n",
    "        y_probs = model.predict(images, batch_size=1, verbose=0)\n",
    "        # Combine previous labels/preds with new labels/preds\n",
    "        y_true.extend(labels)\n",
    "        y_pred_probs.extend(y_probs)\n",
    "    ## Convert the lists to arrays\n",
    "    y_true = np.array(y_true)\n",
    "    y_pred_probs = np.array(y_pred_probs)\n",
    "    \n",
    "    return y_true, y_pred_probs\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21dcb03a-ee39-4e29-9c09-23c85acbf18c",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# Using the function\n",
    "y_test, y_pred_test = get_true_pred_labels(model2, test_ds)\n",
    "print(f'Shape of y_test: {y_test.shape}')\n",
    "print(f'Example of y_test: {y_test[0]}')\n",
    "print(f'Shape of y_pred_test {y_pred_test.shape}')\n",
    "print(f'Example of y_pred_test {y_pred_test[0]}')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94351364-f918-4060-a461-284e111383f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_y_to_sklearn_classes(y, verbose=False):\n",
    "    # If already one-dimension\n",
    "    if np.ndim(y)==1:\n",
    "        if verbose:\n",
    "            print(\"- y is 1D, using it as-is.\")\n",
    "        return y\n",
    "        \n",
    "    # If 2 dimensions with more than 1 column:\n",
    "    elif y.shape[1]>1:\n",
    "        if verbose:\n",
    "            print(\"- y is 2D with >1 column. Using argmax for metrics.\")   \n",
    "        return np.argmax(y, axis=1)\n",
    "    \n",
    "    else:\n",
    "        if verbose:\n",
    "            print(\"y is 2D with 1 column. Using round for metrics.\")\n",
    "        return np.round(y).flatten().astype(int)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d13ce68b-1547-4bfe-8849-790b65927a84",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test function\n",
    "y_preds_transformed = convert_y_to_sklearn_classes(y_pred_test, verbose = True)\n",
    "y_preds_transformed[:5]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79a8845a-35b6-42fd-bed2-8d612347347f",
   "metadata": {},
   "outputs": [],
   "source": [
    "## PREVIOUS CLASSIFICATION_METRICS FUNCTION FROM INTRO TO ML\n",
    "from sklearn.metrics import classification_report, ConfusionMatrixDisplay\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "def classification_metrics(y_true, y_pred, label='',\n",
    "                           output_dict=False, figsize=(8,4),\n",
    "                           normalize='true', cmap='Blues',\n",
    "                           colorbar=False,values_format=\".2f\"):\n",
    "    \"\"\"Modified version of classification metrics function from Intro to Machine Learning.\n",
    "    Updates:\n",
    "    - Reversed raw counts confusion matrix cmap  (so darker==more).\n",
    "    - Added arg for normalized confusion matrix values_format\n",
    "    \"\"\"\n",
    "    # Get the classification report\n",
    "    report = classification_report(y_true, y_pred)\n",
    "    \n",
    "    ## Print header and report\n",
    "    header = \"-\"*70\n",
    "    print(header, f\" Classification Metrics: {label}\", header, sep='\\n')\n",
    "    print(report)\n",
    "    \n",
    "    ## CONFUSION MATRICES SUBPLOTS\n",
    "    fig, axes = plt.subplots(ncols=2, figsize=figsize)\n",
    "    \n",
    "    # Create a confusion matrix  of raw counts (left subplot)\n",
    "    ConfusionMatrixDisplay.from_predictions(y_true, y_pred,\n",
    "                                            normalize=None, \n",
    "                                            cmap='gist_gray_r',# Updated cmap\n",
    "                                            values_format=\"d\", \n",
    "                                            colorbar=colorbar,\n",
    "                                            ax = axes[0]);\n",
    "    axes[0].set_title(\"Raw Counts\")\n",
    "\n",
    "    \n",
    "    # Create a confusion matrix with the data with normalize argument \n",
    "    ConfusionMatrixDisplay.from_predictions(y_true, y_pred,\n",
    "                                            normalize=normalize,\n",
    "                                            cmap=cmap, \n",
    "                                            values_format=values_format, #New arg\n",
    "                                            colorbar=colorbar,\n",
    "                                            ax = axes[1]);\n",
    "    axes[1].set_title(\"Normalized Confusion Matrix\")\n",
    "    \n",
    "    # Adjust layout and show figure\n",
    "    fig.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Return dictionary of classification_report\n",
    "    if output_dict==True:\n",
    "        report_dict = classification_report(y_true, y_pred, output_dict=True)\n",
    "        return report_dict\n",
    "\n",
    "\n",
    "\n",
    "## PLOT_HISTORY FUNCTION FROM WEEK 3\n",
    "def plot_history(history,figsize=(6,8)):\n",
    "    # Get a unique list of metrics \n",
    "    all_metrics = np.unique([k.replace('val_','') for k in history.history.keys()])\n",
    "\n",
    "    # Plot each metric\n",
    "    n_plots = len(all_metrics)\n",
    "    fig, axes = plt.subplots(nrows=n_plots, figsize=figsize)\n",
    "    axes = axes.flatten()\n",
    "\n",
    "    # Loop through metric names add get an index for the axes\n",
    "    for i, metric in enumerate(all_metrics):\n",
    "\n",
    "        # Get the epochs and metric values\n",
    "        epochs = history.epoch\n",
    "        score = history.history[metric]\n",
    "\n",
    "        # Plot the training results\n",
    "        axes[i].plot(epochs, score, label=metric, marker='.')\n",
    "        # Plot val results (if they exist)\n",
    "        try:\n",
    "            val_score = history.history[f\"val_{metric}\"]\n",
    "            axes[i].plot(epochs, val_score, label=f\"val_{metric}\",marker='.')\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "        finally:\n",
    "            axes[i].legend()\n",
    "            axes[i].set(title=metric, xlabel=\"Epoch\",ylabel=metric)\n",
    "\n",
    "    # Adjust subplots and show\n",
    "    fig.tight_layout()\n",
    "    plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddd6c9c0-f04c-4863-8b0a-989433840d85",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_classification_network(model, \n",
    "                                    X_train=None, y_train=None, \n",
    "                                    X_test=None, y_test=None,\n",
    "                                    history=None, history_figsize=(6,6),\n",
    "                                    figsize=(6,4), normalize='true',\n",
    "                                    output_dict = False,\n",
    "                                    cmap_train='Blues',\n",
    "                                    cmap_test=\"Reds\",\n",
    "                                    values_format=\".2f\", \n",
    "                                    colorbar=False):\n",
    "    \"\"\"Evaluates a neural network classification task using either\n",
    "    separate X and y arrays or a tensorflow Dataset\n",
    "    \n",
    "    Data Args:\n",
    "        X_train (array, or Dataset)\n",
    "        y_train (array, or None if using a Dataset\n",
    "        X_test (array, or Dataset)\n",
    "        y_test (array, or None if using a Dataset)\n",
    "        history (history object)\n",
    "        \"\"\"\n",
    "    # Plot history, if provided\n",
    "    if history is not None:\n",
    "        plot_history(history, figsize=history_figsize)\n",
    "    ## Adding a Print Header\n",
    "    print(\"\\n\"+'='*80)\n",
    "    print('- Evaluating Network...')\n",
    "    print('='*80)\n",
    "    ## TRAINING DATA EVALUATION\n",
    "    # check if X_train was provided\n",
    "    if X_train is not None:\n",
    "        ## Check if X_train is a dataset\n",
    "        if hasattr(X_train,'map'):\n",
    "            # If it IS a Datset:\n",
    "            # extract y_train and y_train_pred with helper function\n",
    "            y_train, y_train_pred = get_true_pred_labels(model, X_train)\n",
    "        else:\n",
    "            # Get predictions for training data\n",
    "            y_train_pred = model.predict(X_train)\n",
    "        ## Pass both y-vars through helper compatibility function\n",
    "        y_train = convert_y_to_sklearn_classes(y_train)\n",
    "        y_train_pred = convert_y_to_sklearn_classes(y_train_pred)\n",
    "        \n",
    "        # Call the helper function to obtain regression metrics for training data\n",
    "        results_train = classification_metrics(y_train, y_train_pred, \n",
    "                                         output_dict=True, figsize=figsize,\n",
    "                                             colorbar=colorbar, cmap=cmap_train,\n",
    "                                               values_format=values_format,\n",
    "                                         label='Training Data')\n",
    "        \n",
    "        ## Run model.evaluate         \n",
    "        print(\"\\n- Evaluating Training Data:\")\n",
    "        print(model.evaluate(X_train, return_dict=True))\n",
    "    \n",
    "    # If no X_train, then save empty list for results_train\n",
    "    else:\n",
    "        results_train = []\n",
    "    ## TEST DATA EVALUATION\n",
    "    # check if X_test was provided\n",
    "    if X_test is not None:\n",
    "        ## Check if X_train is a dataset\n",
    "        if hasattr(X_test,'map'):\n",
    "            # If it IS a Datset:\n",
    "            # extract y_train and y_train_pred with helper function\n",
    "            y_test, y_test_pred = get_true_pred_labels(model, X_test)\n",
    "        else:\n",
    "            # Get predictions for training data\n",
    "            y_test_pred = model.predict(X_test)\n",
    "        ## Pass both y-vars through helper compatibility function\n",
    "        y_test = convert_y_to_sklearn_classes(y_test)\n",
    "        y_test_pred = convert_y_to_sklearn_classes(y_test_pred)\n",
    "        \n",
    "        # Call the helper function to obtain regression metrics for training data\n",
    "        results_test = classification_metrics(y_test, y_test_pred, \n",
    "                                         output_dict=True, figsize=figsize,\n",
    "                                             colorbar=colorbar, cmap=cmap_test,\n",
    "                                              values_format=values_format,\n",
    "                                         label='Test Data')\n",
    "        \n",
    "        ## Run model.evaluate         \n",
    "        print(\"\\n- Evaluating Test Data:\")\n",
    "        print(model.evaluate(X_test, return_dict=True))\n",
    "      \n",
    "    # If no X_test, then save empty list for results_test\n",
    "    else:\n",
    "        results_test = []\n",
    "      \n",
    "    # Store results in a dictionary\n",
    "    results_dict = {'train':results_train,\n",
    "                    'test': results_test}\n",
    "    if output_dict == True:\n",
    "        return results_dict\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aca0a526-139e-4d02-ae99-ad7b8151a154",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing with the CNN + Dataset\n",
    "evaluate_classification_network(model2, X_test=test_ds, history=history);\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d6f406f-1c8f-4e5b-8777-9fa0e8b410f9",
   "metadata": {},
   "source": [
    "# Tuning CNNs with Keras Tuner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ca8d615-2c71-482c-9342-6d9f1c2b3e56",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "# Set the seed for NumPy\n",
    "np.random.seed(42)\n",
    "# Set the seed for TensorFlow\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "import os, glob\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import PIL\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.utils import load_img, img_to_array, array_to_img\n",
    "from tensorflow.keras import layers, models\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "import visualkeras as vk\n",
    "\n",
    "import keras_tuner as kt\n",
    "from keras_tuner import HyperParameters as hp\n",
    "\n",
    "import os\n",
    "\n",
    "folder = 'KerasTuner/'\n",
    "os.makedirs(folder, exist_ok=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bb3bb2c-c6ce-4c6a-a057-e25cfe9eb155",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_true_pred_labels(model,ds):\n",
    "    \"\"\"Gets the labels and predicted probabilities from a Tensorflow model and Dataset object.\n",
    "    Adapted from source: https://stackoverflow.com/questions/66386561/keras-classification-report-accuracy-is-different-between-model-predict-accurac\n",
    "    \"\"\"\n",
    "    y_true = []\n",
    "    y_pred_probs = []\n",
    "    \n",
    "    # Loop through the dataset as a numpy iterator\n",
    "    for images, labels in ds.as_numpy_iterator():\n",
    "        \n",
    "        # Get prediction with batch_size=1\n",
    "        y_probs = model.predict(images, batch_size=1, verbose=0)\n",
    "        # Combine previous labels/preds with new labels/preds\n",
    "        y_true.extend(labels)\n",
    "        y_pred_probs.extend(y_probs)\n",
    "    ## Convert the lists to arrays\n",
    "    y_true = np.array(y_true)\n",
    "    y_pred_probs = np.array(y_pred_probs)\n",
    "    \n",
    "    return y_true, y_pred_probs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d324fe6f-f2fe-49f4-b3e0-c6fce7fa74ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_y_to_sklearn_classes(y, verbose=False):\n",
    "    # If already one-dimension\n",
    "    if np.ndim(y)==1:\n",
    "        if verbose:\n",
    "            print(\"- y is 1D, using it as-is.\")\n",
    "        return y\n",
    "        \n",
    "    # If 2 dimensions with more than 1 column:\n",
    "    elif y.shape[1]>1:\n",
    "        if verbose:\n",
    "            print(\"- y is 2D with >1 column. Using argmax for metrics.\")   \n",
    "        return np.argmax(y, axis=1)\n",
    "    \n",
    "    else:\n",
    "        if verbose:\n",
    "            print(\"y is 2D with 1 column. Using round for metrics.\")\n",
    "        return np.round(y).flatten().astype(int)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f29b86b-fea5-4558-a007-3d193cd037ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "## PREVIOUS CLASSIFICATION_METRICS FUNCTION FROM INTRO TO ML\n",
    "from sklearn.metrics import classification_report, ConfusionMatrixDisplay\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "def classification_metrics(y_true, y_pred, label='',\n",
    "                           output_dict=False, figsize=(8,4),\n",
    "                           normalize='true', cmap='Blues',\n",
    "                           colorbar=False,values_format=\".2f\"):\n",
    "    \"\"\"Modified version of classification metrics function from Intro to Machine Learning.\n",
    "    Updates:\n",
    "    - Reversed raw counts confusion matrix cmap  (so darker==more).\n",
    "    - Added arg for normalized confusion matrix values_format\n",
    "    \"\"\"\n",
    "    # Get the classification report\n",
    "    report = classification_report(y_true, y_pred)\n",
    "    \n",
    "    ## Print header and report\n",
    "    header = \"-\"*70\n",
    "    print(header, f\" Classification Metrics: {label}\", header, sep='\\n')\n",
    "    print(report)\n",
    "    \n",
    "    ## CONFUSION MATRICES SUBPLOTS\n",
    "    fig, axes = plt.subplots(ncols=2, figsize=figsize)\n",
    "    \n",
    "    # Create a confusion matrix  of raw counts (left subplot)\n",
    "    ConfusionMatrixDisplay.from_predictions(y_true, y_pred,\n",
    "                                            normalize=None, \n",
    "                                            cmap='gist_gray_r',# Updated cmap\n",
    "                                            values_format=\"d\", \n",
    "                                            colorbar=colorbar,\n",
    "                                            ax = axes[0]);\n",
    "    axes[0].set_title(\"Raw Counts\")\n",
    "\n",
    "    \n",
    "    # Create a confusion matrix with the data with normalize argument \n",
    "    ConfusionMatrixDisplay.from_predictions(y_true, y_pred,\n",
    "                                            normalize=normalize,\n",
    "                                            cmap=cmap, \n",
    "                                            values_format=values_format, #New arg\n",
    "                                            colorbar=colorbar,\n",
    "                                            ax = axes[1]);\n",
    "    axes[1].set_title(\"Normalized Confusion Matrix\")\n",
    "    \n",
    "    # Adjust layout and show figure\n",
    "    fig.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Return dictionary of classification_report\n",
    "    if output_dict==True:\n",
    "        report_dict = classification_report(y_true, y_pred, output_dict=True)\n",
    "        return report_dict\n",
    "\n",
    "\n",
    "\n",
    "## PLOT_HISTORY FUNCTION FROM WEEK 3\n",
    "def plot_history(history,figsize=(6,8)):\n",
    "    # Get a unique list of metrics \n",
    "    all_metrics = np.unique([k.replace('val_','') for k in history.history.keys()])\n",
    "\n",
    "    # Plot each metric\n",
    "    n_plots = len(all_metrics)\n",
    "    fig, axes = plt.subplots(nrows=n_plots, figsize=figsize)\n",
    "    axes = axes.flatten()\n",
    "\n",
    "    # Loop through metric names add get an index for the axes\n",
    "    for i, metric in enumerate(all_metrics):\n",
    "\n",
    "        # Get the epochs and metric values\n",
    "        epochs = history.epoch\n",
    "        score = history.history[metric]\n",
    "\n",
    "        # Plot the training results\n",
    "        axes[i].plot(epochs, score, label=metric, marker='.')\n",
    "        # Plot val results (if they exist)\n",
    "        try:\n",
    "            val_score = history.history[f\"val_{metric}\"]\n",
    "            axes[i].plot(epochs, val_score, label=f\"val_{metric}\",marker='.')\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "        finally:\n",
    "            axes[i].legend()\n",
    "            axes[i].set(title=metric, xlabel=\"Epoch\",ylabel=metric)\n",
    "\n",
    "    # Adjust subplots and show\n",
    "    fig.tight_layout()\n",
    "    plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a310c90-0148-445c-b8b6-a8af9af150b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_classification_network(model, \n",
    "                                    X_train=None, y_train=None, \n",
    "                                    X_test=None, y_test=None,\n",
    "                                    history=None, history_figsize=(6,6),\n",
    "                                    figsize=(6,4), normalize='true',\n",
    "                                    output_dict = False,\n",
    "                                    cmap_train='Blues',\n",
    "                                    cmap_test=\"Reds\",\n",
    "                                    values_format=\".2f\", \n",
    "                                    colorbar=False):\n",
    "    \"\"\"Evaluates a neural network classification task using either\n",
    "    separate X and y arrays or a tensorflow Dataset\n",
    "    \n",
    "    Data Args:\n",
    "        X_train (array, or Dataset)\n",
    "        y_train (array, or None if using a Dataset\n",
    "        X_test (array, or Dataset)\n",
    "        y_test (array, or None if using a Dataset)\n",
    "        history (history object)\n",
    "        \"\"\"\n",
    "    # Plot history, if provided\n",
    "    if history is not None:\n",
    "        plot_history(history, figsize=history_figsize)\n",
    "    ## Adding a Print Header\n",
    "    print(\"\\n\"+'='*80)\n",
    "    print('- Evaluating Network...')\n",
    "    print('='*80)\n",
    "    ## TRAINING DATA EVALUATION\n",
    "    # check if X_train was provided\n",
    "    if X_train is not None:\n",
    "        ## Check if X_train is a dataset\n",
    "        if hasattr(X_train,'map'):\n",
    "            # If it IS a Datset:\n",
    "            # extract y_train and y_train_pred with helper function\n",
    "            y_train, y_train_pred = get_true_pred_labels(model, X_train)\n",
    "        else:\n",
    "            # Get predictions for training data\n",
    "            y_train_pred = model.predict(X_train)\n",
    "        ## Pass both y-vars through helper compatibility function\n",
    "        y_train = convert_y_to_sklearn_classes(y_train)\n",
    "        y_train_pred = convert_y_to_sklearn_classes(y_train_pred)\n",
    "        \n",
    "        # Call the helper function to obtain regression metrics for training data\n",
    "        results_train = classification_metrics(y_train, y_train_pred, \n",
    "                                         output_dict=True, figsize=figsize,\n",
    "                                             colorbar=colorbar, cmap=cmap_train,\n",
    "                                               values_format=values_format,\n",
    "                                         label='Training Data')\n",
    "        \n",
    "        ## Run model.evaluate         \n",
    "        print(\"\\n- Evaluating Training Data:\")\n",
    "        print(model.evaluate(X_train, return_dict=True))\n",
    "    \n",
    "    # If no X_train, then save empty list for results_train\n",
    "    else:\n",
    "        results_train = []\n",
    "    ## TEST DATA EVALUATION\n",
    "    # check if X_test was provided\n",
    "    if X_test is not None:\n",
    "        ## Check if X_train is a dataset\n",
    "        if hasattr(X_test,'map'):\n",
    "            # If it IS a Datset:\n",
    "            # extract y_train and y_train_pred with helper function\n",
    "            y_test, y_test_pred = get_true_pred_labels(model, X_test)\n",
    "        else:\n",
    "            # Get predictions for training data\n",
    "            y_test_pred = model.predict(X_test)\n",
    "        ## Pass both y-vars through helper compatibility function\n",
    "        y_test = convert_y_to_sklearn_classes(y_test)\n",
    "        y_test_pred = convert_y_to_sklearn_classes(y_test_pred)\n",
    "        \n",
    "        # Call the helper function to obtain regression metrics for training data\n",
    "        results_test = classification_metrics(y_test, y_test_pred, \n",
    "                                         output_dict=True, figsize=figsize,\n",
    "                                             colorbar=colorbar, cmap=cmap_test,\n",
    "                                              values_format=values_format,\n",
    "                                         label='Test Data')\n",
    "        \n",
    "        ## Run model.evaluate         \n",
    "        print(\"\\n- Evaluating Test Data:\")\n",
    "        print(model.evaluate(X_test, return_dict=True))\n",
    "      \n",
    "    # If no X_test, then save empty list for results_test\n",
    "    else:\n",
    "        results_test = []\n",
    "      \n",
    "    # Store results in a dictionary\n",
    "    results_dict = {'train':results_train,\n",
    "                    'test': results_test}\n",
    "    if output_dict == True:\n",
    "        return results_dict\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b317ea00-4d91-43f8-b96e-2f4b98907ceb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking the contents of dataset folder (YOUR PATH MAY BE DIFFERENT!)\n",
    "data_dir = \"Data/CatsvsDogs/dataset/\"\n",
    "data_dir\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b7e233c-2428-4f45-90b2-a343dc8bf77d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting the list of folders in the data_dir\n",
    "os.listdir(data_dir)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4f32489-4487-40e9-b8e8-4b9e64d71206",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting list of all img file paths (ONLY, did not make recursive so no folders were included)\n",
    "img_files = glob.glob(data_dir+\"**/**/*\")#, recursive=True)\n",
    "len(img_files)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58ce1171-260e-49bc-b15b-134cf8731d13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting the # of images in the training_set folder\n",
    "train_folder = data_dir+\"training_set/\"\n",
    "print(train_folder)\n",
    "len(glob.glob(train_folder + \"**/*\"))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc0771c8-8c6b-4788-a760-5ce857ff3d12",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_folder = data_dir+\"test_set/\"\n",
    "print(test_folder)\n",
    "len(glob.glob(test_folder + \"**/*\"))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04cd0876-3f3c-4152-8629-2ca067696463",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving image params as vars for reuse\n",
    "batch_size = 32\n",
    "img_height = 64\n",
    "img_width = 64\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9be4fc87-ae33-4a88-bb5b-f4f8b0efb965",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make the dataset from the main folder of images\n",
    "train_ds = tf.keras.utils.image_dataset_from_directory(\n",
    "    train_folder,\n",
    "    shuffle=True,\n",
    "    label_mode='categorical',\n",
    "    seed=123,\n",
    "    image_size=(img_height, img_width),\n",
    "    batch_size=batch_size)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff8790fc-8742-4de1-85bf-41d75e070ecf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make the dataset from the main folder of images\n",
    "test_ds, val_ds = tf.keras.utils.image_dataset_from_directory(\n",
    "    test_folder,\n",
    "    validation_split=.5,\n",
    "    subset='both',\n",
    "    shuffle=True,\n",
    "    label_mode='categorical',\n",
    "    seed=123,\n",
    "    image_size=(img_height, img_width),\n",
    "    batch_size=batch_size)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66183764-73ae-4eb2-9571-c9e1b6977798",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preview an example image (at full size)\n",
    "img_loaded = load_img(img_files[0])\n",
    "display(img_loaded)\n",
    "\n",
    "#Get shape of image file\n",
    "img_data = img_to_array(img_loaded)\n",
    "img_data.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cae1a169-964a-4015-b338-e192886a6102",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving the class names\n",
    "class_names = train_ds.class_names\n",
    "class_names\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e868a4e5-b8b1-4891-a8eb-45e2e896aa04",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving a dictionary with class labels:names\n",
    "class_dict = dict(zip(range(len(class_names)), class_names))\n",
    "class_dict\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0acb8b8-be77-49a8-a6b0-0958da621bcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# taking a sample banch to see batch shape\n",
    "example_batch_imgs,example_batch_y= train_ds.take(1).get_single_element()\n",
    "example_batch_imgs.shape\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5085838a-50b1-46ea-b9d6-b19a3f3f4be2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking shape of a single y\n",
    "display(example_batch_y[0])\n",
    "print(example_batch_y[0].shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30af38e2-4829-4d8a-9e89-de7ff74cdfe9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preview an image from the Dataset\n",
    "array_to_img(example_batch_imgs[0])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1933aa3-e3c3-437d-8c16-2c6ec62af39b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# individual image shape\n",
    "input_shape = example_batch_imgs[0].shape\n",
    "input_shape\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "442f6aef-bce2-4aff-98f5-b9d72db2d28d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model1():\n",
    "    \n",
    "    model = models.Sequential(name=\"Model1\")\n",
    "    # Using rescaling layer to scale pixel values\n",
    "    model.add(layers.Rescaling(1./255, input_shape=input_shape))\n",
    "    \n",
    "    # Convolutional layer #1\n",
    "    model.add( layers.Conv2D(filters=16,  kernel_size=3, padding='same') ) \n",
    "    # Pooling layer #1\n",
    "    model.add( layers.MaxPooling2D(pool_size=2, strides=1))\n",
    "    \n",
    "    # Convolutional layer #2\n",
    "    model.add( layers.Conv2D(filters=16, kernel_size=3, padding='same')) \n",
    "    # Pooling layer #2\n",
    "    model.add(layers.MaxPooling2D(pool_size=2, strides=1))\n",
    "    \n",
    "    # Flattening layer\n",
    "    model.add(layers.Flatten())\n",
    "    # # Output layer\n",
    "    model.add(\n",
    "        layers.Dense(len(class_names), activation=\"softmax\")\n",
    "    )\n",
    "    \n",
    "    model.compile(optimizer='adam',\n",
    "                  loss=tf.keras.losses.BinaryCrossentropy(),\n",
    "                  metrics=['accuracy'])\n",
    "    \n",
    "    model.summary()\n",
    "    return model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9b05ea6-e16c-416a-97e1-18413b97f97e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build model and visualize\n",
    "model1 = build_model1()\n",
    "vk.layered_view(model1, legend=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e19aa295-6f7d-4780-a3bf-b87c0b5c9d66",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_callbacks(patience=3, monitor='val_accuracy'):\n",
    "    early_stop = tf.keras.callbacks.EarlyStopping(patience=patience, monitor=monitor)\n",
    "    return [early_stop]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9412778a-7ec8-4cff-81c8-64936d09a779",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build new model and fit \n",
    "model1 = build_model1()\n",
    "history = model1.fit(\n",
    "    train_ds, validation_data=val_ds, epochs=25, callbacks=get_callbacks()\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94419b2f-75cb-4929-bccd-3b824e3b7c23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the model using the evaluation function\n",
    "evaluate_classification_network(\n",
    "    model1, X_train=train_ds, X_test=test_ds, history=history);\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72d31bff-94b7-4c05-9813-f7ad01895e60",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model_dense():\n",
    "    model = models.Sequential(name='Model2')\n",
    "    model.add(layers.Rescaling(1. / 255, input_shape=input_shape))\n",
    "    # Conv2d/MaxPooling #1\n",
    "    model.add(layers.Conv2D(16, kernel_size=3, padding='same'))\n",
    "    model.add(layers.MaxPooling2D(2, strides=1))\n",
    "    # Conv2d/MaxPooling #2\n",
    "    model.add(layers.Conv2D(16, kernel_size=3,padding='same'))\n",
    "    model.add(layers.MaxPooling2D(2, strides=1))\n",
    "    model.add(layers.Flatten())\n",
    "    ## NEW Hidden Dense layer\n",
    "    model.add(layers.Dense(256, activation=\"relu\"))\n",
    "    model.add(layers.Dense(len(class_names), activation=\"softmax\"))\n",
    "    model.compile(\n",
    "        optimizer=\"adam\",\n",
    "        loss=tf.keras.losses.BinaryCrossentropy(),\n",
    "        metrics=[\n",
    "            \"accuracy\"]\n",
    "    )\n",
    "    return model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37a9c9b6-4a3b-465d-aa28-45be0dbcd219",
   "metadata": {},
   "outputs": [],
   "source": [
    "model2 = build_model_dense()\n",
    "display(vk.layered_view(model2, legend=True))\n",
    "model2.summary()\n",
    "# fit the neural network\n",
    "history = model2.fit(\n",
    "    train_ds, validation_data=val_ds, epochs=25, callbacks=get_callbacks()\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb55536b-100e-4044-94b6-d032b2a1025a",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate_classification_network(\n",
    "    model2, X_train=train_ds,  X_test=test_ds, history=history);\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ead54fba-dbe8-4406-80f4-ef045cd923cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_tune_model_deep(hp):\n",
    "    model = models.Sequential()\n",
    "    model.add(layers.Rescaling(1.0 / 255, input_shape=input_shape))\n",
    "    # Setting hp params and saving as var so they can be used at >1 layer\n",
    "    n_filters = hp.Int('filters_1',min_value=16, max_value=64, step=16)\n",
    "    pool_strides = hp.Choice('pool_strides',[1,2])\n",
    "    \n",
    "    model.add(layers.Conv2D(n_filters,\n",
    "                            # Test using larger kernel size (in first Conv layer ONLY)\n",
    "                            kernel_size= hp.Choice('kernel_size_1',[3,5]),\n",
    "                            padding='same')\n",
    "             )\n",
    "    model.add(layers.MaxPooling2D(2, strides=pool_strides))\n",
    "    for i in range(hp.Int('n_conv_layers',min_value=1, max_value=3)):\n",
    "        # Double the number of filters vs. previous layer\n",
    "        n_filters = n_filters * 2\n",
    "        model.add(layers.Conv2D(n_filters, kernel_size=3, padding='same'))\n",
    "        model.add(layers.MaxPooling2D(2, strides=pool_strides))\n",
    "        \n",
    "        # model.add(layers.Dropout(hp.Float('dropout_rate',min_value=0.1, max_value=0.5, step=.1)))\n",
    "    # Final layers\n",
    "    model.add(layers.Flatten())\n",
    "    model.add(layers.Dense(n_filters, activation=\"relu\"))\n",
    "    # Test various dropout strengths\n",
    "    model.add(layers.Dropout(hp.Float('dropout_rate_dense',min_value=0, max_value=0.5,\n",
    "                                     step=.1)))\n",
    "    model.add(layers.Dense(len(class_names), activation=\"softmax\"))\n",
    "    model.compile(\n",
    "        optimizer=\"adam\",\n",
    "        loss=tf.keras.losses.BinaryCrossentropy(),\n",
    "        metrics=[\n",
    "            \"accuracy\"],\n",
    "    )\n",
    "    return model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91309392-e919-4b89-be80-ed578815e3ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the tuner\n",
    "tuner_hb = kt.Hyperband(build_tune_model_deep, objective='val_accuracy',\n",
    "                        max_epochs=15, overwrite=True, seed=321,) \n",
    "# Preivew search summary\n",
    "tuner_hb.search_space_summary()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52d9e349-78d8-4d7d-ad09-bf4f4a39d0ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start search\n",
    "tuner_hb.search(train_ds, validation_data=val_ds, epochs=25)\n",
    "# Obtain summary of results\n",
    "tuner_hb.results_summary()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e3c4eee-60b6-4881-9dfd-c1cb7cdeb754",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the results for beset paramters\n",
    "print(f\"Best Params: \\n {tuner_hb.get_best_hyperparameters()[0].values}\" )\n",
    "# Define the best model\n",
    "best_model = tuner_hb.get_best_models()[0]\n",
    "# Evalute the best model with the custom evaluation function\n",
    "evaluate_classification_network(best_model, X_train=train_ds, X_test=test_ds);\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "520b6102-0f1e-4b73-ae39-ed902c11e96a",
   "metadata": {},
   "source": [
    "# Transfer Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dccf638-e97b-4c49-9828-19c91f1e536d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "# Set the seed for NumPy\n",
    "np.random.seed(42)\n",
    "# Set the seed for TensorFlow\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "import os, glob\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.utils import load_img, img_to_array, array_to_img\n",
    "from tensorflow.keras import layers, models\n",
    "import visualkeras as vk\n",
    "tf.__version__\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81626e9f-1417-4433-b0c3-aab8943afd3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking the contents of folder\n",
    "data_dir = \"Data/CatsvsDogs/dataset/\"\n",
    "# Training Folder \n",
    "train_folder = data_dir+\"training_set/\"\n",
    "# Test folder\n",
    "test_folder = data_dir+\"test_set/\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b60b42ce-3644-4d38-bc6c-efc12f77dbb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving image params as vars for reuse\n",
    "batch_size = 32\n",
    "img_height = 128\n",
    "img_width = 128\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1d7670a-678e-4955-9c3d-f435e36e70dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make the dataset from the main folder of images\n",
    "train_ds = tf.keras.utils.image_dataset_from_directory(\n",
    "    train_folder,\n",
    "    shuffle=True,\n",
    "    label_mode='categorical', \n",
    "    seed=123,\n",
    "    image_size=(img_height,img_width),\n",
    "    batch_size=batch_size)\n",
    "\n",
    "## Split the test data 50/50 validation/test\n",
    "test_ds, val_ds = tf.keras.utils.image_dataset_from_directory(\n",
    "    test_folder,\n",
    "    validation_split=.5,\n",
    "    subset='both',\n",
    "    shuffle=True,\n",
    "    label_mode='categorical',\n",
    "    seed=123,\n",
    "    image_size=(img_width, img_height),\n",
    "    batch_size=batch_size)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "034df98a-7ce0-4a97-9d26-97a80d66a2a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# checking the class names\n",
    "class_names = train_ds.class_names\n",
    "class_dict = dict(zip(range(len(class_names)), class_names))\n",
    "class_dict\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea3fa7f2-02f3-4eba-be62-99705b815aa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Programmatically saving input_shape from training data\n",
    "example_batch_imgs, example_batch_labels = train_ds.take(1).get_single_element()\n",
    "input_shape = example_batch_imgs[0].shape\n",
    "input_shape\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "330792fb-a5f7-4ca7-b85a-89c02c2aab34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use autotune to automatically determine best buffer sizes \n",
    "AUTOTUNE = tf.data.AUTOTUNE\n",
    "\n",
    "# optimize\n",
    "train_ds = train_ds.cache().shuffle(buffer_size= len(train_ds), seed=42).prefetch(buffer_size=AUTOTUNE)\n",
    "val_ds = val_ds.cache().prefetch(buffer_size=AUTOTUNE)\n",
    "test_ds = test_ds.cache().prefetch(buffer_size=AUTOTUNE)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca91e509-9af8-484f-8cec-7950de0aa7f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Downloading the full model (for demonstration only)\n",
    "vgg16_full = tf.keras.applications.VGG16(include_top = True, weights = 'imagenet')\n",
    "vgg16_full.summary()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fda23e8-5acc-467d-83b2-6e58cc21e2b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the model with visualkeras\n",
    "vk.layered_view(vgg16_full, legend=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f68ee95d-e983-496b-b665-dda40506f42d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Downloading just the convolutional base\n",
    "vgg16_base = tf.keras.applications.VGG16(include_top = False, weights = 'imagenet', input_shape=input_shape)\n",
    "vgg16_base.summary()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8677433-93c5-4e9a-9db0-679e0f65c5b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "vk.layered_view(vgg16_base, legend=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46b5c601-b2c5-4b26-a169-6bf902ba1a6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if base is trainable\n",
    "vgg16_base.trainable\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6ab20d0-ccfd-4bcc-93a6-4702760b2fe9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prevent layers from base_model from changing\n",
    "vgg16_base.trainable = False\n",
    "vgg16_base.trainable\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f11570c-5523-4abc-a5b1-4827be5604d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.keras.applications.vgg16.preprocess_input?\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "793fb6cb-c23a-49c4-aa41-02cd25a8ddbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a lambda layer for the preprocess input function for the model\n",
    "lambda_layer_vgg16 = tf.keras.layers.Lambda(tf.keras.applications.vgg16.preprocess_input,                                       name='preprocess_input')\n",
    "lambda_layer_vgg16\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c77608d9-1d8d-418b-954b-e97681eb9dc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Downloading just the convolutional base\n",
    "vgg16_base = tf.keras.applications.VGG16(\n",
    "    include_top=False, weights=\"imagenet\", input_shape=input_shape\n",
    ")\n",
    "# Prevent layers from base_model from changing \n",
    "vgg16_base.trainable = False\n",
    "\n",
    "# Create the preprocessing lamdba layer\n",
    "# Create a lambda layer for the preprocess input function for the model\n",
    "lambda_layer_vgg16 = tf.keras.layers.Lambda(\n",
    "    tf.keras.applications.vgg16.preprocess_input, name=\"preprocess_input\"\n",
    ")\n",
    "\n",
    "\n",
    "def build_vgg16_model():\n",
    "    model = models.Sequential(name=\"VGG16\")\n",
    "    # Use input layer (lambda layer will handle rescaling).\n",
    "    model.add(tf.keras.layers.Input(shape=input_shape))\n",
    "\n",
    "    ## Adding preprocessing lamabda layer\n",
    "    model.add(lambda_layer_vgg16)\n",
    "\n",
    "    # Add pretrained base\n",
    "    model.add(vgg16_base)\n",
    "\n",
    "    # Flattening layer\n",
    "    model.add(layers.Flatten())\n",
    "\n",
    "    ## Adding a Hidden Dense Layer\n",
    "    model.add(layers.Dense(256, activation=\"relu\"))\n",
    "    model.add(layers.Dropout(0.5))\n",
    "\n",
    "    # Output layer\n",
    "    model.add(layers.Dense(len(class_names), activation=\"softmax\"))\n",
    "\n",
    "    model.compile(\n",
    "        optimizer=tf.keras.optimizers.legacy.Adam(),\n",
    "        loss=tf.keras.losses.CategoricalCrossentropy(),\n",
    "        metrics=[\"accuracy\"],\n",
    "    )\n",
    "    model.summary()\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35be26a4-a609-4d65-a991-130fd18d6235",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_callbacks(monitor='val_accuracy', patience=3, restore_best_weights=False):\n",
    "    early_stopping = tf.keras.callbacks.EarlyStopping(patience=patience, \n",
    "                                                      restore_best_weights=restore_best_weights)\n",
    "    return [early_stopping]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "353b6ed5-236b-46d8-9fc7-de73219fe0b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_vgg16 = build_vgg16_model()\n",
    "model_vgg16.summary()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "709d3933-c940-4931-ad0b-c41f40d5d0f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_vgg16=build_vgg16_model()\n",
    "history = model_vgg16.fit(train_ds, validation_data=val_ds,epochs=20, \n",
    "                    callbacks=get_callbacks()\n",
    "                         )\n",
    "evaluate_classification_network(model_vgg16,X_test=test_ds,history=history);\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3ba87fd-2cca-4a6a-b7cb-1657c4af2606",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download EfficientNet base\n",
    "efficientnet_base =tf.keras.applications.EfficientNetB0(include_top=False, input_shape=input_shape)\n",
    "\n",
    "# Make it not-trainable\n",
    "efficientnet_base.trainable=False\n",
    "vk.layered_view(efficientnet_base, legend=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7856db4-af3b-4caa-954e-f84c3bfebd9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add preprocessing lambda layer\n",
    "lambda_layer_efficient = tf.keras.layers.Lambda(tf.keras.applications.efficientnet.preprocess_input, \n",
    "                                      name='preprocess_input_enet')\n",
    "\n",
    "def build_efficientnet_model():\n",
    "    model = models.Sequential(name=\"EfficientNetB0\")\n",
    "    # Use input layer (lambda layer will handle rescaling).\n",
    "    model.add(tf.keras.layers.Input(shape=input_shape))\n",
    "\n",
    "    ## Adding preprocessing lamabda layer\n",
    "    model.add(lambda_layer_efficient)\n",
    "\n",
    "    # Add pretrained base\n",
    "    model.add(efficientnet_base)\n",
    "\n",
    "    # Flattening layer\n",
    "    model.add(layers.Flatten())\n",
    "\n",
    "    ## Adding a Hidden Dense Layer\n",
    "    model.add(layers.Dense(256, activation=\"relu\"))\n",
    "    model.add(layers.Dropout(0.5))\n",
    "\n",
    "    # Output layer\n",
    "    model.add(layers.Dense(len(class_names), activation=\"softmax\"))\n",
    "\n",
    "    model.compile(\n",
    "        optimizer=tf.keras.optimizers.legacy.Adam(),\n",
    "        loss=tf.keras.losses.CategoricalCrossentropy(),\n",
    "        metrics=[\"accuracy\"],\n",
    "    )\n",
    "    model.summary()\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1853e914-6da3-470a-b5ac-6e0e7e73d2fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build, fit, and evaluate EfficientNet Model\n",
    "model_effnet = build_efficientnet_model()\n",
    "history = model_effnet.fit(train_ds, validation_data=val_ds,epochs=20, \n",
    "                    callbacks=get_callbacks()\n",
    "                   )\n",
    "evaluate_classification_network(model_effnet, X_test=test_ds, history=history);\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a38c982f-1934-4c1f-b7b0-bab36704cf68",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download Inception Base and prevent it from learning\n",
    "inception_base = tf.keras.applications.InceptionV3(include_top=False, input_shape=input_shape)\n",
    "\n",
    "# prevent training of transfer model\n",
    "inception_base.trainable = False\n",
    "vk.layered_view(inception_base, legend=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55e1042b-4833-4093-985e-6ded8bf8b5ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add preprocessing lambda layer\n",
    "lambda_layer_inception = tf.keras.layers.Lambda(tf.keras.applications.inception_v3.preprocess_input, \n",
    "                                      name='preprocess_input_inceptv3')\n",
    "\n",
    "def build_inception_model():\n",
    "    model = models.Sequential(name=\"InceptionV3\")\n",
    "    # Use input layer (lambda layer will handle rescaling).\n",
    "    model.add(tf.keras.layers.Input(shape=input_shape))\n",
    "\n",
    "    ## Adding preprocessing lamabda layer\n",
    "    model.add(lambda_layer_inception)\n",
    "\n",
    "    # Add pretrained base\n",
    "    model.add(inception_base)\n",
    "\n",
    "    # Flattening layer\n",
    "    model.add(layers.Flatten())\n",
    "\n",
    "    ## Adding a Hidden Dense Layer\n",
    "    model.add(layers.Dense(256, activation=\"relu\"))\n",
    "    model.add(layers.Dropout(0.5))\n",
    "\n",
    "    # Output layer\n",
    "    model.add(layers.Dense(len(class_names), activation=\"softmax\"))\n",
    "\n",
    "    model.compile(\n",
    "        optimizer=tf.keras.optimizers.legacy.Adam(),\n",
    "        loss=tf.keras.losses.CategoricalCrossentropy(),\n",
    "        metrics=[\"accuracy\"],\n",
    "    )\n",
    "    model.summary()\n",
    "    return model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e062906-be02-4ffd-bbb6-21c6567770f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build, fit, and evaluate EfficientNet Model\n",
    "model_inception = build_inception_model()\n",
    "history = model_inception.fit(train_ds, validation_data=val_ds,epochs=20, \n",
    "                    callbacks=get_callbacks()\n",
    "                   )\n",
    "evaluate_classification_network(model_inception, X_test=test_ds, history=history);\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02b28966-8ee8-4362-8dc3-82900fe1c2f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select the best model\n",
    "best_model = model_vgg16 #model_effnet\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c354dfc7-d2e3-4a13-bf06-9b6c411a20c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "folder = 'BestModels/'\n",
    "os.makedirs(folder, exist_ok=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7df3ccb-4387-4cb0-afbb-a256eca8a662",
   "metadata": {},
   "outputs": [],
   "source": [
    "# saving the best model\n",
    "model_fname = 'BestModels/best-transfer-learning-to-explain.keras'\n",
    "best_model.save(model_fname)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c77f7c5d-5924-45df-b6aa-466e928f5166",
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_model = tf.keras.models.load_model(model_fname)\n",
    "loaded_model.summary()\n",
    "evaluate_classification_network(loaded_model, X_test=test_ds, history=history);\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56f792ec-b791-4d98-aa63-166c8fb79976",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68432b15-d1cb-4544-abbc-81368f2db7c6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (dojo-env)",
   "language": "python",
   "name": "dojo-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
